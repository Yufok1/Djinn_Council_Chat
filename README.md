# ğŸŒ‚ Djinn Council Chat - Mystical Multi-Agent AI Orchestration

> *"Command legions of AI djinn in mystical council - where collective intelligence meets ethereal beauty"*

A sophisticated multi-agent AI orchestration system that coordinates multiple AI models (djinn) to provide comprehensive, multi-perspective responses through an enchanting graphical interface.

![Python Version](https://img.shields.io/badge/python-3.7+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Ollama](https://img.shields.io/badge/ollama-required-orange.svg)

## âœ¨ Features

### ğŸ­ **Multi-Agent Council System**
- **6 Specialized AI Djinn**: Each with unique roles and expertise
  - ğŸ§™â€â™‚ï¸ **Strategist**: Long-term planning and recursive analysis
  - ğŸ“Š **Analyst**: Technical breakdowns and data analysis
  - âš–ï¸ **Arbiter**: Conflict resolution and balanced judgment
  - ğŸ›¡ï¸ **Guardian**: Risk assessment and security analysis
  - ğŸ—ï¸ **Architect**: System design and implementation frameworks
  - ğŸ“š **Historian**: Historical context and precedent analysis

### ğŸŒŒ **Advanced Consensus Algorithms**
- **Majority Vote**: Democratic decision-making
- **Confidence Scoring**: Expertise-based selection
- **Weighted Roles**: Hierarchical authority system
- **Deliberative Loop**: Iterative refinement
- **Hybrid**: Multiple perspective presentation

### ğŸ¨ **Mystical GUI Experience**
- **Dark Arcane Theme**: Stunning ethereal aesthetics
- **Live Thinking Visualization**: See AI models contemplate in real-time
- **Typewriter Layout**: Organized response display
- **Crystalline Confidence Indicators**: Visual confidence levels
- **Unlimited Thinking Time**: Models can think as long as needed

### ğŸ§  **Advanced Memory System**
- **Persistent Conversations**: Across all sessions
- **User Profile Learning**: Adapts to your preferences
- **Conversation Summarization**: Intelligent context management
- **Cross-Model Memory**: Shared context for all djinn

### ğŸ”’ **Enterprise-Grade Features**
- **Security Safeguards**: Prompt injection detection
- **Integrity Monitoring**: Response validation
- **State Machine Architecture**: Robust session management
- **Performance Optimization**: Persistent worker threads

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.7+** installed
2. **Ollama** installed and running
   ```bash
   # Install Ollama (visit https://ollama.ai for instructions)
   ollama --version
   
   # Pull at least one model
   ollama pull llama3.2:latest
   ```

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Yufok1/Djinn_Council_Chat.git
   cd Djinn_Council_Chat
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Launch the mystical interface**
   ```bash
   python djinn_council_gui_enhanced.py
   ```

## ğŸ“– Usage Guide

### Basic Operation

1. **Start the GUI**: Run `python djinn_council_gui_enhanced.py`
2. **Configure Models**: Assign Ollama models to each djinn role
3. **Select Consensus Mode**: Choose how the council reaches decisions
4. **Ask Questions**: Type your query and click "INVOKE COUNCIL"
5. **Watch the Magic**: Observe live thinking processes and mystical responses

### Advanced Features

#### Model Assignment
- Each djinn can use a different Ollama model
- Supports advanced models like DeepSeek with thinking capabilities
- Automatic model detection and validation

#### Consensus Modes
- **Weighted Roles**: Balanced hierarchy (Recommended)
- **Confidence Scoring**: Trust the most confident
- **Majority Vote**: Democratic consensus
- **Hybrid**: See all perspectives
- **Deliberative Loop**: Multi-round discussion

#### Memory Management
- **View Stats**: Check conversation history and user profile
- **Clear Memory**: Reset conversation (keeping or removing profile)
- **Persistent Learning**: System remembers your preferences

### Command Line Interface

For advanced users, direct CLI access is available:

```bash
# Advanced council with full CISM
python advanced_djinn_council.py "Your question here"

# With specific consensus mode
python advanced_djinn_council.py --mode majority_vote "Your question"

# System status
python advanced_djinn_council.py --status
```

## ğŸ—ï¸ Architecture

### Core Components

1. **Advanced Djinn Council** (`advanced_djinn_council.py`)
   - Council Invocation State Machine (CISM)
   - Integrity safeguards and security
   - Advanced consensus algorithms
   - Performance optimizations

2. **GUI Interface** (`djinn_council_gui_enhanced.py`)
   - Mystical visual interface
   - Live thinking visualization
   - Real-time orchestration
   - Configuration management

3. **Conversational Memory** (`conversational_memory.py`)
   - Persistent memory system
   - User profile learning
   - Context management
   - Conversation summarization

### Data Flow

1. **Query Input** â†’ Security validation â†’ Context enrichment
2. **Parallel Execution** â†’ All djinn process simultaneously
3. **Response Collection** â†’ Confidence scoring â†’ Integrity checks
4. **Consensus Algorithm** â†’ Final response generation
5. **Memory Storage** â†’ User profile updates â†’ Session logging

## ğŸ”§ Configuration

### Model Configuration
Models are configured in `advanced_djinn_config.json`:

```json
{
  "roles": {
    "strategist": {
      "model_name": "llama3.2:latest",
      "priority_weight": 1.2,
      "confidence_threshold": 0.8
    }
  }
}
```

### Security Settings
- Prompt injection detection
- Input sanitization
- Command whitelisting
- Pattern blocking

### Performance Tuning
- Concurrent session limits
- Context truncation
- Unlimited thinking time
- Worker thread management

## ğŸ›¡ï¸ Security Features

- **Prompt Injection Detection**: Advanced pattern recognition
- **Input Sanitization**: Automatic content filtering
- **Recursion Depth Limiting**: Prevents infinite loops
- **Session Isolation**: Secure multi-user support
- **Integrity Monitoring**: Response validation and consistency

## ğŸ“ File Structure

```
djinn_council_chat/
â”œâ”€â”€ djinn_council_gui_enhanced.py    # Main GUI application
â”œâ”€â”€ advanced_djinn_council.py        # Core council system
â”œâ”€â”€ conversational_memory.py         # Memory management
â”œâ”€â”€ djinn_council.py                 # Legacy council
â”œâ”€â”€ djinn_council_gui.py             # Legacy GUI
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ advanced_djinn_config.json       # Advanced configuration
â”œâ”€â”€ djinn_council_config.json        # Legacy configuration
â”œâ”€â”€ research & development/          # Documentation and research
â”œâ”€â”€ launch_*.bat                     # Windows launcher scripts
â””â”€â”€ djinn_memory/                    # User memory storage (auto-created)
```

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/mystical-enhancement`)
3. Commit your changes (`git commit -am 'Add mystical feature'`)
4. Push to the branch (`git push origin feature/mystical-enhancement`)
5. Create a Pull Request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/your-username/Djinn_Council_Chat.git

# Install development dependencies
pip install -r requirements.txt

# Run tests (if available)
python -m pytest tests/
```

## ğŸ› Troubleshooting

### Common Issues

**Ollama not found**
```bash
# Ensure Ollama is installed and in PATH
ollama --version
```

**Models not loading**
```bash
# Pull required models
ollama pull llama3.2:latest
ollama list
```

**GUI not starting**
- Ensure Python tkinter is installed
- Check Python version (3.7+ required)
- Verify all dependencies are installed

### Debug Mode

Enable detailed logging in configuration:
```json
{
  "logging_settings": {
    "log_level": "DEBUG",
    "enable_detailed_logging": true
  }
}
```

## ğŸ“Š Performance

### Benchmarks
- **Startup Time**: < 3 seconds
- **Response Time**: Varies by model (unlimited thinking time)
- **Memory Usage**: ~100MB base + model memory
- **Concurrent Sessions**: Up to 5 (configurable)

### Optimization Tips
- Use SSD storage for faster model loading
- Assign faster models to high-priority roles
- Adjust context limits for better performance
- Enable parallel execution (default)

## ğŸ—ºï¸ Roadmap

### Planned Features
- [ ] Plugin system for custom djinn
- [ ] Web interface option
- [ ] Model fine-tuning integration
- [ ] Voice interaction support
- [ ] Export/import conversation history
- [ ] Custom consensus algorithms
- [ ] Multi-language support

### Version History
- **v1.0**: Initial mystical release with GUI
- **v0.9**: Advanced council with CISM
- **v0.8**: Memory system integration
- **v0.7**: Security and integrity features
- **v0.6**: Basic multi-agent system

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Ollama Project**: For providing the local LLM infrastructure
- **Python Community**: For the excellent libraries
- **AI Research Community**: For inspiring multi-agent architectures
- **Fantasy Literature**: For the mystical djinn concept

## ğŸ“¬ Contact

- **GitHub Issues**: [Report bugs and request features](https://github.com/Yufok1/Djinn_Council_Chat/issues)
- **Discussions**: [Community discussions](https://github.com/Yufok1/Djinn_Council_Chat/discussions)

---

*"In the realm where code meets consciousness, the djinn council awaits your command..."* âœ¨ğŸŒ‚âœ¨